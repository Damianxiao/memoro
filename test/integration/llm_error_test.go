package integration

import (
	"context"
	"os"
	"strings"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"memoro/internal/config"
	"memoro/internal/models"
	"memoro/internal/services/llm"
)

// TestLLMErrorHandling æµ‹è¯•LLMé”™è¯¯å¤„ç†
func TestLLMErrorHandling(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	client, err := llm.NewClient()
	require.NoError(t, err)

	t.Run("æµ‹è¯•è¶…æ—¶å¤„ç†", func(t *testing.T) {
		// åˆ›å»ºä¸€ä¸ªå¾ˆçŸ­çš„è¶…æ—¶ä¸Šä¸‹æ–‡
		ctx, cancel := context.WithTimeout(context.Background(), 1*time.Millisecond)
		defer cancel()

		messages := []llm.ChatMessage{
			{Role: "user", Content: "è¯·è¯¦ç»†è§£é‡Šäººå·¥æ™ºèƒ½çš„å‘å±•å†å²"},
		}

		_, err := client.ChatCompletion(ctx, messages)
		assert.Error(t, err, "åº”è¯¥å› ä¸ºè¶…æ—¶è€Œè¿”å›é”™è¯¯")
		t.Logf("âœ… è¶…æ—¶é”™è¯¯å¤„ç†æ­£å¸¸: %v", err)
	})

	t.Run("æµ‹è¯•ç©ºæ¶ˆæ¯å¤„ç†", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		// æµ‹è¯•ç©ºæ¶ˆæ¯åˆ—è¡¨
		_, err := client.ChatCompletion(ctx, []llm.ChatMessage{})
		assert.Error(t, err, "ç©ºæ¶ˆæ¯åˆ—è¡¨åº”è¯¥è¿”å›é”™è¯¯")

		// æµ‹è¯•ç©ºå†…å®¹æ¶ˆæ¯
		messages := []llm.ChatMessage{
			{Role: "user", Content: ""},
		}
		_, err = client.ChatCompletion(ctx, messages)
		assert.Error(t, err, "ç©ºå†…å®¹æ¶ˆæ¯åº”è¯¥è¿”å›é”™è¯¯")

		t.Logf("âœ… ç©ºæ¶ˆæ¯é”™è¯¯å¤„ç†æ­£å¸¸")
	})

	t.Run("æµ‹è¯•æ— æ•ˆè§’è‰²å¤„ç†", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		messages := []llm.ChatMessage{
			{Role: "invalid_role", Content: "æµ‹è¯•å†…å®¹"},
		}

		// è¿™å¯èƒ½ä¼šè¢«APIæ¥å—æˆ–æ‹’ç»ï¼Œæˆ‘ä»¬ä¸»è¦æµ‹è¯•å®¢æˆ·ç«¯ä¸ä¼šå´©æºƒ
		_, err := client.ChatCompletion(ctx, messages)
		// æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½ä¸åº”è¯¥panic
		t.Logf("âœ… æ— æ•ˆè§’è‰²å¤„ç†ç»“æœ: %v", err)
	})
}

// TestLLMContentBoundaries æµ‹è¯•å†…å®¹è¾¹ç•Œæƒ…å†µ
func TestLLMContentBoundaries(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	client, err := llm.NewClient()
	require.NoError(t, err)

	summarizer, err := llm.NewSummarizer(client)
	require.NoError(t, err)

	tagger, err := llm.NewTagger(client)
	require.NoError(t, err)

	t.Run("æµ‹è¯•å¤§å†…å®¹å¤„ç†", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
		defer cancel()

		// åˆ›å»ºæ¥è¿‘æœ€å¤§é™åˆ¶çš„å†…å®¹ (100KB = 102400å­—èŠ‚)
		largeContent := strings.Repeat("è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æµ‹è¯•å†…å®¹ã€‚", 3000) // çº¦30KB
		
		// æµ‹è¯•æ‘˜è¦ç”Ÿæˆ
		summaryRequest := llm.SummaryRequest{
			Content:     largeContent,
			ContentType: models.ContentTypeText,
		}

		result, err := summarizer.GenerateSummary(ctx, summaryRequest)
		if err != nil {
			t.Logf("å¤§å†…å®¹æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼ˆå¯èƒ½è¶…å‡ºé™åˆ¶ï¼‰: %v", err)
		} else {
			assert.NotNil(t, result, "å¤§å†…å®¹æ‘˜è¦åº”è¯¥æˆåŠŸç”Ÿæˆ")
			t.Logf("âœ… å¤§å†…å®¹æ‘˜è¦ç”ŸæˆæˆåŠŸï¼Œå†…å®¹é•¿åº¦: %d", len(largeContent))
		}
	})

	t.Run("æµ‹è¯•è¶…å¤§å†…å®¹å¤„ç†", func(t *testing.T) {
		// åˆ›å»ºè¶…è¿‡æœ€å¤§é™åˆ¶çš„å†…å®¹
		oversizeContent := strings.Repeat("æµ‹è¯•å†…å®¹", 20000) // çº¦200KBï¼Œè¶…è¿‡100KBé™åˆ¶

		summaryRequest := llm.SummaryRequest{
			Content:     oversizeContent,
			ContentType: models.ContentTypeText,
		}

		_, err := summarizer.GenerateSummary(context.Background(), summaryRequest)
		assert.Error(t, err, "è¶…å¤§å†…å®¹åº”è¯¥è¿”å›é”™è¯¯")
		t.Logf("âœ… è¶…å¤§å†…å®¹é”™è¯¯å¤„ç†æ­£å¸¸: %v", err)
	})

	t.Run("æµ‹è¯•ç‰¹æ®Šå­—ç¬¦å†…å®¹", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		specialContent := "æµ‹è¯•ç‰¹æ®Šå­—ç¬¦ï¼š@#$%^&*(){}[]|\\:;\"'<>,.?/~`! ğŸš€ğŸ‰ğŸ’¡ğŸ”¥â­ Î±Î²Î³Î´Îµ ä¸­æ–‡æµ‹è¯•"

		// æµ‹è¯•æ‘˜è¦
		summaryRequest := llm.SummaryRequest{
			Content:     specialContent,
			ContentType: models.ContentTypeText,
		}

		result, err := summarizer.GenerateSummary(ctx, summaryRequest)
		require.NoError(t, err, "ç‰¹æ®Šå­—ç¬¦å†…å®¹å¤„ç†åº”è¯¥æˆåŠŸ")
		assert.NotEmpty(t, result.OneLine, "ç‰¹æ®Šå­—ç¬¦æ‘˜è¦ä¸åº”ä¸ºç©º")

		// æµ‹è¯•æ ‡ç­¾
		tagRequest := llm.TagRequest{
			Content:     specialContent,
			ContentType: models.ContentTypeText,
			MaxTags:     5,
		}

		tagResult, err := tagger.GenerateTags(ctx, tagRequest)
		require.NoError(t, err, "ç‰¹æ®Šå­—ç¬¦æ ‡ç­¾ç”Ÿæˆåº”è¯¥æˆåŠŸ")
		assert.NotEmpty(t, tagResult.Tags, "ç‰¹æ®Šå­—ç¬¦æ ‡ç­¾ä¸åº”ä¸ºç©º")

		t.Logf("âœ… ç‰¹æ®Šå­—ç¬¦å¤„ç†æµ‹è¯•æˆåŠŸ")
	})

	t.Run("æµ‹è¯•å¤šè¯­è¨€å†…å®¹", func(t *testing.T) {
		ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
		defer cancel()

		multilingualContent := `Hello world! ä½ å¥½ä¸–ç•Œï¼ã“ã‚“ã«ã¡ã¯ä¸–ç•Œï¼Bonjour le monde! 
		Hola mundo! ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€! Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…! 
		This is a multilingual test content with different scripts and languages.
		è¿™æ˜¯ä¸€ä¸ªå¤šè¯­è¨€æµ‹è¯•å†…å®¹ï¼ŒåŒ…å«ä¸åŒçš„æ–‡å­—å’Œè¯­è¨€ã€‚`

		summaryRequest := llm.SummaryRequest{
			Content:     multilingualContent,
			ContentType: models.ContentTypeText,
		}

		result, err := summarizer.GenerateSummary(ctx, summaryRequest)
		require.NoError(t, err, "å¤šè¯­è¨€å†…å®¹å¤„ç†åº”è¯¥æˆåŠŸ")
		assert.NotEmpty(t, result.OneLine, "å¤šè¯­è¨€æ‘˜è¦ä¸åº”ä¸ºç©º")

		t.Logf("âœ… å¤šè¯­è¨€å¤„ç†æµ‹è¯•æˆåŠŸ")
		t.Logf("ğŸŒ å¤šè¯­è¨€æ‘˜è¦: %s", result.OneLine)
	})
}

// TestLLMRateLimitAndRetry æµ‹è¯•é€Ÿç‡é™åˆ¶å’Œé‡è¯•æœºåˆ¶
func TestLLMRateLimitAndRetry(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	client, err := llm.NewClient()
	require.NoError(t, err)

	t.Run("æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†", func(t *testing.T) {
		// åˆ›å»ºå¤šä¸ªå¹¶å‘è¯·æ±‚
		concurrentRequests := 3
		results := make(chan error, concurrentRequests)

		for i := 0; i < concurrentRequests; i++ {
			go func(index int) {
				ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
				defer cancel()

				messages := []llm.ChatMessage{
					{Role: "user", Content: "ç®€å•æµ‹è¯•è¯·æ±‚ " + string(rune(index+'1'))},
				}

				_, err := client.ChatCompletion(ctx, messages)
				results <- err
			}(i)
		}

		// æ”¶é›†ç»“æœ
		successCount := 0
		for i := 0; i < concurrentRequests; i++ {
			err := <-results
			if err == nil {
				successCount++
			} else {
				t.Logf("å¹¶å‘è¯·æ±‚ %d å¤±è´¥: %v", i+1, err)
			}
		}

		assert.Greater(t, successCount, 0, "è‡³å°‘åº”æœ‰ä¸€ä¸ªå¹¶å‘è¯·æ±‚æˆåŠŸ")
		t.Logf("âœ… å¹¶å‘è¯·æ±‚æµ‹è¯•å®Œæˆï¼ŒæˆåŠŸ: %d/%d", successCount, concurrentRequests)
	})
}

// TestLLMConfigurationValidation æµ‹è¯•é…ç½®éªŒè¯
func TestLLMConfigurationValidation(t *testing.T) {
	t.Run("æµ‹è¯•é…ç½®åŠ è½½", func(t *testing.T) {
		cfg, err := config.Load("../../config/app.yaml")
		require.NoError(t, err, "é…ç½®åŠ è½½åº”è¯¥æˆåŠŸ")

		// éªŒè¯LLMé…ç½®
		assert.Equal(t, "openai_compatible", cfg.LLM.Provider, "Provideråº”è¯¥åŒ¹é…")
		assert.Equal(t, "https://api.gpt.ge/v1", cfg.LLM.APIBase, "API Baseåº”è¯¥åŒ¹é…third-part-ai.md")
		assert.Equal(t, "gpt-4o", cfg.LLM.Model, "Modelåº”è¯¥åŒ¹é…third-part-ai.md")
		assert.Equal(t, 1688, cfg.LLM.MaxTokens, "MaxTokensåº”è¯¥åŒ¹é…")
		assert.Equal(t, 0.5, cfg.LLM.Temperature, "Temperatureåº”è¯¥åŒ¹é…")

		// éªŒè¯å¤„ç†é…ç½®
		assert.Equal(t, 102400, cfg.Processing.MaxContentSize, "MaxContentSizeåº”è¯¥ä¸º100KB")
		assert.Equal(t, 200, cfg.Processing.SummaryLevels.OneLineMaxLength, "ä¸€å¥è¯æ‘˜è¦é•¿åº¦é™åˆ¶")
		assert.Equal(t, 1000, cfg.Processing.SummaryLevels.ParagraphMaxLength, "æ®µè½æ‘˜è¦é•¿åº¦é™åˆ¶")
		assert.Equal(t, 5000, cfg.Processing.SummaryLevels.DetailedMaxLength, "è¯¦ç»†æ‘˜è¦é•¿åº¦é™åˆ¶")
		assert.Equal(t, 50, cfg.Processing.TagLimits.MaxTags, "æœ€å¤§æ ‡ç­¾æ•°é‡")
		assert.Equal(t, 100, cfg.Processing.TagLimits.MaxTagLength, "æ ‡ç­¾æœ€å¤§é•¿åº¦")
		assert.Equal(t, 0.7, cfg.Processing.TagLimits.DefaultConfidence, "é»˜è®¤ç½®ä¿¡åº¦")

		t.Logf("âœ… é…ç½®éªŒè¯å®Œæˆ")
	})

	t.Run("æµ‹è¯•ç¯å¢ƒå˜é‡åŠ è½½", func(t *testing.T) {
		apiKey := os.Getenv("MEMORO_LLM_API_KEY")
		if apiKey != "" {
			assert.True(t, strings.HasPrefix(apiKey, "sk-"), "API Keyåº”è¯¥ä»¥sk-å¼€å¤´")
			assert.Greater(t, len(apiKey), 20, "API Keyé•¿åº¦åº”è¯¥åˆç†")
			t.Logf("âœ… API Keyæ ¼å¼éªŒè¯é€šè¿‡")
		} else {
			t.Log("âš ï¸  MEMORO_LLM_API_KEYæœªè®¾ç½®")
		}
	})
}