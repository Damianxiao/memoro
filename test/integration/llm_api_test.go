package integration

import (
	"context"
	"os"
	"testing"
	"time"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"memoro/internal/config"
	"memoro/internal/models"
	"memoro/internal/services/llm"
)

// TestLLMAPIConnection æµ‹è¯•LLM APIåŸºç¡€è¿æ¥
func TestLLMAPIConnection(t *testing.T) {
	// æ£€æŸ¥æ˜¯å¦æœ‰API Keyç¯å¢ƒå˜é‡
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	cfg, err := config.Load("../../config/app.yaml")
	require.NoError(t, err, "Failed to load config")
	require.NotEmpty(t, cfg.LLM.APIKey, "LLM API key should be loaded from environment")

	// åˆ›å»ºLLMå®¢æˆ·ç«¯
	client, err := llm.NewClient()
	require.NoError(t, err, "Failed to create LLM client")
	require.NotNil(t, client, "LLM client should not be nil")

	// æµ‹è¯•åŸºç¡€èŠå¤©åŠŸèƒ½ï¼ˆä½¿ç”¨third-part-ai.mdä¸­çš„ç¤ºä¾‹ï¼‰
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	messages := []llm.ChatMessage{
		{Role: "user", Content: "æ™šä¸Šå¥½"},
	}

	response, err := client.ChatCompletion(ctx, messages)
	require.NoError(t, err, "API call should succeed")
	require.NotNil(t, response, "Response should not be nil")

	// éªŒè¯å“åº”æ ¼å¼ç¬¦åˆthird-part-ai.mdè§„èŒƒ
	assert.NotEmpty(t, response.ID, "Response should have ID")
	assert.Equal(t, "chat.completion", response.Object, "Object should be chat.completion")
	assert.Greater(t, response.Created, int64(0), "Created timestamp should be positive")
	assert.NotEmpty(t, response.Model, "Model should not be empty")
	assert.NotEmpty(t, response.Choices, "Choices should not be empty")
	assert.Greater(t, response.Usage.TotalTokens, 0, "Total tokens should be positive")

	// éªŒè¯ç¬¬ä¸€ä¸ªé€‰æ‹©çš„å†…å®¹
	choice := response.Choices[0]
	assert.Equal(t, 0, choice.Index, "First choice index should be 0")
	assert.Equal(t, "assistant", choice.Message.Role, "Response role should be assistant")
	assert.NotEmpty(t, choice.Message.Content, "Response content should not be empty")
	assert.Equal(t, "stop", choice.FinishReason, "Finish reason should be stop")

	t.Logf("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ")
	t.Logf("ğŸ“Š Tokenä½¿ç”¨: %d prompt + %d completion = %d total", 
		response.Usage.PromptTokens, 
		response.Usage.CompletionTokens, 
		response.Usage.TotalTokens)
	t.Logf("ğŸ¤– å“åº”å†…å®¹: %s", choice.Message.Content)
}

// TestLLMSimpleCompletion æµ‹è¯•ç®€å•å®ŒæˆåŠŸèƒ½
func TestLLMSimpleCompletion(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®å¹¶åˆ›å»ºå®¢æˆ·ç«¯
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	client, err := llm.NewClient()
	require.NoError(t, err)

	// æµ‹è¯•ç®€å•å®Œæˆ
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	systemPrompt := "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹æ‘˜è¦åŠ©æ‰‹ã€‚"
	userPrompt := "è¯·ä¸ºä»¥ä¸‹å†…å®¹ç”Ÿæˆä¸€å¥è¯æ‘˜è¦ï¼šäººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œç‰¹åˆ«æ˜¯åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå–å¾—äº†é‡å¤§çªç ´ã€‚"

	response, err := client.SimpleCompletion(ctx, systemPrompt, userPrompt)
	require.NoError(t, err, "Simple completion should succeed")
	assert.NotEmpty(t, response, "Response should not be empty")

	t.Logf("âœ… ç®€å•å®Œæˆæµ‹è¯•æˆåŠŸ")
	t.Logf("ğŸ“ ç”Ÿæˆçš„æ‘˜è¦: %s", response)
}

// TestLLMSummarizerIntegration æµ‹è¯•æ‘˜è¦ç”Ÿæˆå™¨é›†æˆ
func TestLLMSummarizerIntegration(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	// åˆ›å»ºå®¢æˆ·ç«¯å’Œæ‘˜è¦ç”Ÿæˆå™¨
	client, err := llm.NewClient()
	require.NoError(t, err)

	summarizer, err := llm.NewSummarizer(client)
	require.NoError(t, err)
	require.NotNil(t, summarizer, "Summarizer should not be nil")

	// æµ‹è¯•æ‘˜è¦ç”Ÿæˆ
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	testContent := `äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè¯•å›¾åˆ›å»ºèƒ½å¤Ÿä»¥ç±»ä¼¼äººç±»æ™ºèƒ½çš„æ–¹å¼æ„ŸçŸ¥ã€å­¦ä¹ ã€æ¨ç†å’Œè§£å†³é—®é¢˜çš„æœºå™¨å’Œè½¯ä»¶ã€‚AIçš„å‘å±•å†ç¨‹å¯ä»¥è¿½æº¯åˆ°20ä¸–çºª50å¹´ä»£ï¼Œå½“æ—¶ç§‘å­¦å®¶ä»¬å¼€å§‹æ¢ç´¢è®©æœºå™¨æ¨¡æ‹Ÿäººç±»æ€ç»´çš„å¯èƒ½æ€§ã€‚

è¿‘å¹´æ¥ï¼Œéšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„çªç ´ï¼ŒAIåœ¨å„ä¸ªé¢†åŸŸéƒ½å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚ä»è¯­éŸ³è¯†åˆ«åˆ°å›¾åƒå¤„ç†ï¼Œä»è‡ªç„¶è¯­è¨€å¤„ç†åˆ°è‡ªåŠ¨é©¾é©¶ï¼ŒAIæŠ€æœ¯æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»æ–¹å¼ã€‚ç‰¹åˆ«æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„å‡ºç°ï¼Œä½¿å¾—AIåœ¨ç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€æ–¹é¢è¾¾åˆ°äº†å‰æ‰€æœªæœ‰çš„æ°´å¹³ã€‚

ç„¶è€Œï¼ŒAIçš„å¿«é€Ÿå‘å±•ä¹Ÿå¸¦æ¥äº†æ–°çš„æŒ‘æˆ˜å’Œä¼¦ç†é—®é¢˜ã€‚å¦‚ä½•ç¡®ä¿AIç³»ç»Ÿçš„å®‰å…¨æ€§ã€å…¬å¹³æ€§å’Œé€æ˜åº¦ï¼Œå¦‚ä½•å¤„ç†AIå¯èƒ½å¸¦æ¥çš„å°±ä¸šå½±å“ï¼Œè¿™äº›éƒ½æ˜¯éœ€è¦æˆ‘ä»¬è®¤çœŸè€ƒè™‘çš„é—®é¢˜ã€‚`

	request := llm.SummaryRequest{
		Content:     testContent,
		ContentType: models.ContentTypeText,
		Context:     map[string]interface{}{"topic": "äººå·¥æ™ºèƒ½"},
	}

	result, err := summarizer.GenerateSummary(ctx, request)
	require.NoError(t, err, "Summary generation should succeed")
	require.NotNil(t, result, "Summary result should not be nil")

	// éªŒè¯ä¸‰å±‚æ¬¡æ‘˜è¦
	assert.NotEmpty(t, result.OneLine, "ä¸€å¥è¯æ‘˜è¦ä¸åº”ä¸ºç©º")
	assert.NotEmpty(t, result.Paragraph, "æ®µè½æ‘˜è¦ä¸åº”ä¸ºç©º")
	assert.NotEmpty(t, result.Detailed, "è¯¦ç»†æ‘˜è¦ä¸åº”ä¸ºç©º")

	// éªŒè¯æ‘˜è¦é•¿åº¦é™åˆ¶
	assert.LessOrEqual(t, len(result.OneLine), 200, "ä¸€å¥è¯æ‘˜è¦åº”ä¸è¶…è¿‡200å­—ç¬¦")
	assert.LessOrEqual(t, len(result.Paragraph), 1000, "æ®µè½æ‘˜è¦åº”ä¸è¶…è¿‡1000å­—ç¬¦")
	assert.LessOrEqual(t, len(result.Detailed), 5000, "è¯¦ç»†æ‘˜è¦åº”ä¸è¶…è¿‡5000å­—ç¬¦")

	t.Logf("âœ… æ‘˜è¦ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
	t.Logf("ğŸ“„ ä¸€å¥è¯æ‘˜è¦ (%då­—ç¬¦): %s", len(result.OneLine), result.OneLine)
	t.Logf("ğŸ“„ æ®µè½æ‘˜è¦ (%då­—ç¬¦): %s", len(result.Paragraph), result.Paragraph)
	t.Logf("ğŸ“„ è¯¦ç»†æ‘˜è¦ (%då­—ç¬¦): %s", len(result.Detailed), result.Detailed)
}

// TestLLMTaggerIntegration æµ‹è¯•æ ‡ç­¾ç”Ÿæˆå™¨é›†æˆ
func TestLLMTaggerIntegration(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	// åˆ›å»ºå®¢æˆ·ç«¯å’Œæ ‡ç­¾ç”Ÿæˆå™¨
	client, err := llm.NewClient()
	require.NoError(t, err)

	tagger, err := llm.NewTagger(client)
	require.NoError(t, err)
	require.NotNil(t, tagger, "Tagger should not be nil")

	// æµ‹è¯•æ ‡ç­¾ç”Ÿæˆ
	ctx, cancel := context.WithTimeout(context.Background(), 60*time.Second)
	defer cancel()

	testContent := `æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚æ·±åº¦å­¦ä¹ ä½œä¸ºæœºå™¨å­¦ä¹ çš„å­é›†ï¼Œä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥åˆ†ææ•°æ®ã€‚è¿™äº›æŠ€æœ¯åœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³å¤„ç†å’Œè‡ªç„¶è¯­è¨€ç†è§£ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚`

	request := llm.TagRequest{
		Content:     testContent,
		ContentType: models.ContentTypeText,
		MaxTags:     10,
		Context:     map[string]interface{}{"domain": "technology"},
	}

	result, err := tagger.GenerateTags(ctx, request)
	require.NoError(t, err, "Tag generation should succeed")
	require.NotNil(t, result, "Tag result should not be nil")

	// éªŒè¯æ ‡ç­¾ç»“æœ
	assert.NotEmpty(t, result.Tags, "æ ‡ç­¾åˆ—è¡¨ä¸åº”ä¸ºç©º")
	assert.LessOrEqual(t, len(result.Tags), 10, "æ ‡ç­¾æ•°é‡ä¸åº”è¶…è¿‡æœ€å¤§é™åˆ¶")
	assert.NotEmpty(t, result.Categories, "åˆ†ç±»åˆ—è¡¨ä¸åº”ä¸ºç©º")
	assert.NotEmpty(t, result.Keywords, "å…³é”®è¯åˆ—è¡¨ä¸åº”ä¸ºç©º")
	assert.NotEmpty(t, result.Confidence, "ç½®ä¿¡åº¦æ˜ å°„ä¸åº”ä¸ºç©º")

	// éªŒè¯æ ‡ç­¾é•¿åº¦
	for _, tag := range result.Tags {
		assert.LessOrEqual(t, len(tag), 100, "æ ‡ç­¾é•¿åº¦ä¸åº”è¶…è¿‡100å­—ç¬¦")
		assert.NotEmpty(t, tag, "æ ‡ç­¾ä¸åº”ä¸ºç©º")
	}

	// éªŒè¯ç½®ä¿¡åº¦
	for tag, confidence := range result.Confidence {
		assert.GreaterOrEqual(t, confidence, 0.0, "ç½®ä¿¡åº¦åº”å¤§äºç­‰äº0")
		assert.LessOrEqual(t, confidence, 1.0, "ç½®ä¿¡åº¦åº”å°äºç­‰äº1")
		assert.Contains(t, result.Tags, tag, "ç½®ä¿¡åº¦æ˜ å°„ä¸­çš„æ ‡ç­¾åº”åœ¨æ ‡ç­¾åˆ—è¡¨ä¸­")
	}

	t.Logf("âœ… æ ‡ç­¾ç”Ÿæˆæµ‹è¯•æˆåŠŸ")
	t.Logf("ğŸ·ï¸ ç”Ÿæˆæ ‡ç­¾ (%dä¸ª): %v", len(result.Tags), result.Tags)
	t.Logf("ğŸ“‚ å†…å®¹åˆ†ç±»: %v", result.Categories)
	t.Logf("ğŸ”‘ å…³é”®è¯: %v", result.Keywords)
}

// TestLLMQuickFunctions æµ‹è¯•å¿«é€ŸåŠŸèƒ½
func TestLLMQuickFunctions(t *testing.T) {
	// æ£€æŸ¥API Key
	apiKey := os.Getenv("MEMORO_LLM_API_KEY")
	if apiKey == "" {
		t.Skip("Skipping LLM API test: MEMORO_LLM_API_KEY not set")
	}

	// åŠ è½½é…ç½®
	_, err := config.Load("../../config/app.yaml")
	require.NoError(t, err)

	// åˆ›å»ºå®¢æˆ·ç«¯
	client, err := llm.NewClient()
	require.NoError(t, err)

	// æµ‹è¯•å¿«é€Ÿæ‘˜è¦
	summarizer, err := llm.NewSummarizer(client)
	require.NoError(t, err)

	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	quickSummary, err := summarizer.GenerateQuickSummary(ctx, "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚", models.ContentTypeText)
	require.NoError(t, err, "Quick summary should succeed")
	assert.NotEmpty(t, quickSummary, "Quick summary should not be empty")

	// æµ‹è¯•ç®€å•æ ‡ç­¾
	tagger, err := llm.NewTagger(client)
	require.NoError(t, err)

	simpleTags, err := tagger.GenerateSimpleTags(ctx, "ä»Šå¤©æ˜¯ä¸ªå¥½æ—¥å­ï¼Œé˜³å…‰æ˜åªšã€‚", models.ContentTypeText, 5)
	require.NoError(t, err, "Simple tags should succeed")
	assert.NotEmpty(t, simpleTags, "Simple tags should not be empty")
	assert.LessOrEqual(t, len(simpleTags), 5, "Tag count should not exceed limit")

	t.Logf("âœ… å¿«é€ŸåŠŸèƒ½æµ‹è¯•æˆåŠŸ")
	t.Logf("âš¡ å¿«é€Ÿæ‘˜è¦: %s", quickSummary)
	t.Logf("âš¡ ç®€å•æ ‡ç­¾: %v", simpleTags)
}